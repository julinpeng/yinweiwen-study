
  bin/zkServer.sh start-foreground
  #windows zkServer.cmd (不要start)
  
 
  bin/kafka-server-start.sh config/server.properties
  #windows>>  bin/windows/kafka-server-start ../../config/server.properties
 
  ./http_server -addr ":8011" -brokers "10.8.30.173:9092"
  
  #创建topic
  ./kafka-topics.sh --create --zookeeper node35:2181,node36:2181,node37:2181 --replication-factor 3 --partitions 1 --topic anxinyun_data
 
  ./kafka-console-producer.sh --broker-list 10.8.30.35:6667,10.8.30.36:6667,10.8.30.37:6667 --topic anxinyun_data

  ./kafka-console-consumer.sh --bootstrap-server 10.8.30.35:6667,10.8.30.36:6667,10.8.30.37:6667 --topic anxinyun_data --from-beginning
  
  // on windows
  // I:\WorkSpace\@JAVA\kafka_2.11-0.11.0.0\bin\windows>kafka-console-consumer.bat --bootstrap-server 10.8.30.117:9092 --topic important --from-beginning
	
  # 查看topic  (describe)
  ./kafka-topics.sh --list --zookeeper node35:2181,node36:2181,node37:2181
  
  ./kafka-topics.sh --zookeeper node35:2181,node36:2181,node37:2181  --describe  --topic anxinyun_data
  ```bash
	Topic:anxinyun_data	PartitionCount:1	ReplicationFactor:1	Configs:
	Topic: anxinyun_data	Partition: 0	Leader: 1003	Replicas: 1003	Isr: 1003
  ```
  
  # 修改分区
  ./kafka-topics.sh --zookeeper node35:2181,node36:2181,node37:2181 --alter --topic anxinyun_data --partitions 3
  
  # 修改副本
  `increase-replication-factor.json`
  ``` json
  {"version":1,
	  "partitions":[
		 {"topic":"anxinyun_data","partition":0,"replicas":[1001,1002,1003]},
		 {"topic":"anxinyun_data","partition":1,"replicas":[1001,1002,1003]},
		 {"topic":"anxinyun_data","partition":2,"replicas":[1001,1002,1003]}
	]}
  ```
  kafka-reassign-partitions --zookeeper node35:2181,node36:2181,node37:2181 --reassignment-json-file increase-replication-factor.json --execute
  
  
  
  # 删除topic
  ./kafka-topics.sh --delete --zookeeper node35:2181,node36:2181,node37:2181 --topic anxinyun_data
  如果 `delete.topic.enable=true` 则直接删除，否则topic仅仅被标记为删除
  从zk中删除topic
  ./zkCli.sh
  ls /brokers/topics
  rmr /brokers/topics/anxinyun_data2
  删除完成后重启zookeeper和kafka服务；
  
  
	
	
  SPARK 
  启动master	./sbin/start-master.sh
  启动slaves	./sbin/start-slave.sh <worker#> <master-spark-URL>
  启动shell		./bin/spark-shell --master spark://IP:PORT
		count.saveAsTextFile("README.md")  不带file://的话，默认保存到hdfs中

报错 java.lang.NumberFormatException: For input string: "E:\xxx\xx"
zoo.cfg
用zkServer start命令报如题的错误，改为直接用zkServer启动则ok
dataDir=E:/★Coding/1workspace/zookeeper-3.4.10/data
		
Eclipse

Windows——>Preferences——>Java-->Editor-->Content Asist，在Auto activation triggers for Java后面的文本框里只有一个“.”。现在你将其改为“.abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ”即可


windows下部署hadoop
Error: JAVA_HOME is incorrectly set.
解决方法： JAVA_HOME不能包含空格
找不到hadoop和yarn文件
解决方法：hadooponwindows-master.zip解压替换hadoop中bin目录 （http://blog.csdn.net/antgan/article/details/52067441）
http://localhost:50070


linq<==>scala
Select is map, 
Aggregate is reduce (or fold),
 SelectMany is flatMap,
 Where is filter or withFilter, 
 orderBy is sort or sortBy or sortWith,
 and there are zip, take and takeWhile
 First is find
 Any is exists
 All is forall
 
 Spark Stream中 Partitioner是个什么鬼？？？

hdfs namenode -format

start-dfs.cmd 中修改
start "Apache Hadoop Distribution" %HADOOP_BIN_PATH%\..\bin\hadoop.cmd namenode
start "Apache Hadoop Distribution" %HADOOP_BIN_PATH%\..\bin\hadoop.cmd datanode

nexus
http://localhost:8081/
http://books.sonatype.com/nexus-book/reference3/install.html#installation-java
nexus.exe /install <optional-service-name>
nexus.exe /start <optional-service-name>
nexus.exe /stop <optional-service-name>
nexus.exe /uninstall <optional-service-name>

maven项目支持scala(IDEA)
File>ProjectStructure>Library>+ScalaSDK  (可能要download)
 
 
 
 postgres备份
 pg_dump -h host1 dbname | psql -h host2 dbname  
 
 
 
 #!/bin/sh
for host in node-1 node-2 node-3
do
	ssh $host "source /etc/profile;/export/servers/zookeeper/bin/zkServer.sh start"
    ssh $host"source/etc/profile;nohup /export/servers/kafka/binkafka-server-start.sh 
	/export/servers/kafka/config/server.properties >/dev/null 2>&1" 
	echo "$host zookeeper&kafka is running"
done

#!/bin/sh
for host in node-1 node-2 node-3
do
	ssh $host "source /etc/profile;bash /export/servers/kafka/bin/kafka-server-stop.sh" 
	ssh $host "source /etc/profile;/export/servers/zookeeper/bin/zkServer.sh stop"
	echo "$host kafka&zookeeper is stopping"
done